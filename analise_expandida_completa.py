import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from scipy import stats
from scipy.stats import chi2_contingency, pearsonr
from factor_analyzer import FactorAnalyzer
from statsmodels.formula.api import ols
from statsmodels.stats.anova import anova_lm
import warnings
warnings.filterwarnings('ignore')

# Configura√ß√£o global para gr√°ficos
plt.style.use('default')
sns.set_palette("husl")
plt.rcParams['figure.figsize'] = (12, 8)
plt.rcParams['font.size'] = 10

def carregar_dados():
    """Carregar todos os datasets"""
    print("üìÅ Carregando datasets...")
    datasets = {}
    
    files = [
        'Qualidade do servi√ßo.csv',
        'Utiliza√ß√£o.csv', 
        'Percep√ß√£o novos servi√ßos.csv',
        'Inten√ß√£o comportamental.csv',
        'Aceita√ß√£o da tecnologia.csv',
        'Experi√™ncia do usu√°rio.csv',
        'Perfil Socioeconomico.csv'
    ]
    
    for file in files:
        try:
            df = pd.read_csv(f'csv_extraidos/{file}', encoding='utf-8')
            name = file.replace('.csv', '').replace(' ', '_').lower()
            datasets[name] = df
            print(f"‚úì {file}: {len(df)} registros, {len(df.columns)} colunas")
        except Exception as e:
            print(f"‚úó Erro ao carregar {file}: {e}")
    
    return datasets

def limpar_colunas(df):
    """Limpar nomes das colunas removendo caracteres especiais"""
    new_columns = []
    for col in df.columns:
        # Remove caracteres especiais comuns
        clean_col = col.strip().replace('\xa0', '').replace('\n', '').replace('\r', '')
        new_columns.append(clean_col)
    df.columns = new_columns
    return df

def analise_perfil_socioeconomico_completa(datasets):
    """An√°lise completa do perfil socioecon√¥mico"""
    print("\nüîç AN√ÅLISE COMPLETA DO PERFIL SOCIOECON√îMICO")
    print("="*60)
    
    df = limpar_colunas(datasets['perfil_socioeconomico'].copy())
    
    # Identificar colunas dinamicamente
    gender_col = None
    race_col = None
    age_col = None
    education_col = None
    profession_col = None
    children_col = None
    income_col = None
    
    for col in df.columns:
        if 'g√™nero' in col.lower() or 'genero' in col.lower():
            gender_col = col
        elif 'ra√ßa' in col.lower() or 'raca' in col.lower():
            race_col = col
        elif 'idade' in col.lower():
            age_col = col
        elif 'escolaridade' in col.lower():
            education_col = col
        elif 'profissional' in col.lower():
            profession_col = col
        elif 'filhos' in col.lower():
            children_col = col
        elif 'renda' in col.lower():
            income_col = col
    
    print(f"Colunas identificadas:")
    print(f"G√™nero: {gender_col}")
    print(f"Ra√ßa: {race_col}")
    print(f"Idade: {age_col}")
    print(f"Escolaridade: {education_col}")
    print(f"Profiss√£o: {profession_col}")
    print(f"Filhos: {children_col}")
    print(f"Renda: {income_col}")
    
    resultados = {}
    
    # 1. AN√ÅLISE DE G√äNERO
    if gender_col:
        print(f"\n1. DISTRIBUI√á√ÉO POR G√äNERO")
        print("-"*30)
        gender_dist = df[gender_col].value_counts()
        gender_pct = df[gender_col].value_counts(normalize=True) * 100
        
        for cat, count in gender_dist.items():
            pct = gender_pct[cat]
            print(f"  {cat}: {count} ({pct:.1f}%)")
        
        resultados['genero'] = {
            'distribuicao': gender_dist.to_dict(),
            'percentuais': gender_pct.to_dict()
        }
    
    # 2. AN√ÅLISE DE ETNIA/RA√áA
    if race_col:
        print(f"\n2. DISTRIBUI√á√ÉO POR ETNIA/RA√áA")
        print("-"*30)
        race_dist = df[race_col].value_counts()
        race_pct = df[race_col].value_counts(normalize=True) * 100
        
        for cat, count in race_dist.items():
            pct = race_pct[cat]
            print(f"  {cat}: {count} ({pct:.1f}%)")
        
        resultados['raca'] = {
            'distribuicao': race_dist.to_dict(),
            'percentuais': race_pct.to_dict()
        }
    
    # 3. AN√ÅLISE DE ESCOLARIDADE
    if education_col:
        print(f"\n3. DISTRIBUI√á√ÉO POR N√çVEL DE ESCOLARIDADE")
        print("-"*40)
        edu_dist = df[education_col].value_counts()
        edu_pct = df[education_col].value_counts(normalize=True) * 100
        
        # Ordenar por ordem educacional
        ordem_educacao = {
            'Fundamental': 1,
            'Ensino M√©dio': 2, 
            'T√©cnico': 2,
            'Gradua√ß√£o': 3,
            'P√≥s-gradua√ß√£o': 4
        }
        
        for cat, count in edu_dist.items():
            pct = edu_pct[cat]
            print(f"  {cat}: {count} ({pct:.1f}%)")
        
        resultados['escolaridade'] = {
            'distribuicao': edu_dist.to_dict(),
            'percentuais': edu_pct.to_dict()
        }
    
    # 4. AN√ÅLISE DE IDADE
    if age_col:
        print(f"\n4. DISTRIBUI√á√ÉO POR FAIXA ET√ÅRIA")
        print("-"*30)
        age_dist = df[age_col].value_counts()
        age_pct = df[age_col].value_counts(normalize=True) * 100
        
        for cat, count in age_dist.items():
            pct = age_pct[cat]
            print(f"  {cat}: {count} ({pct:.1f}%)")
        
        resultados['idade'] = {
            'distribuicao': age_dist.to_dict(),
            'percentuais': age_pct.to_dict()
        }
    
    # 5. AN√ÅLISE DE SITUA√á√ÉO PROFISSIONAL
    if profession_col:
        print(f"\n5. DISTRIBUI√á√ÉO POR SITUA√á√ÉO PROFISSIONAL")
        print("-"*40)
        prof_dist = df[profession_col].value_counts()
        prof_pct = df[profession_col].value_counts(normalize=True) * 100
        
        for cat, count in prof_dist.items():
            pct = prof_pct[cat]
            print(f"  {cat}: {count} ({pct:.1f}%)")
        
        resultados['profissao'] = {
            'distribuicao': prof_dist.to_dict(),
            'percentuais': prof_pct.to_dict()
        }
    
    # 6. AN√ÅLISE DE FILHOS
    if children_col:
        print(f"\n6. DISTRIBUI√á√ÉO POR N√öMERO DE FILHOS")
        print("-"*35)
        try:
            children_dist = df[children_col].value_counts().sort_index()
            children_pct = df[children_col].value_counts(normalize=True).sort_index() * 100
            
            for cat, count in children_dist.items():
                pct = children_pct[cat]
                print(f"  {cat} filhos: {count} ({pct:.1f}%)")
            
            # Estat√≠sticas
            children_numeric = pd.to_numeric(df[children_col], errors='coerce')
            media_filhos = children_numeric.mean()
            print(f"\n  M√©dia de filhos: {media_filhos:.2f}")
            
            resultados['filhos'] = {
                'distribuicao': children_dist.to_dict(),
                'percentuais': children_pct.to_dict(),
                'media': media_filhos
            }
        except Exception as e:
            print(f"  Erro na an√°lise de filhos: {e}")
    
    # 7. AN√ÅLISE DE RENDA
    if income_col:
        print(f"\n7. DISTRIBUI√á√ÉO POR FAIXA DE RENDA")
        print("-"*35)
        income_dist = df[income_col].value_counts()
        income_pct = df[income_col].value_counts(normalize=True) * 100
        
        for cat, count in income_dist.items():
            pct = income_pct[cat]
            print(f"  {cat}: {count} ({pct:.1f}%)")
        
        resultados['renda'] = {
            'distribuicao': income_dist.to_dict(),
            'percentuais': income_pct.to_dict()
        }
    
    return resultados

def analise_utilizacao_completa(datasets):
    """An√°lise completa de utiliza√ß√£o do transporte"""
    print("\nüöå AN√ÅLISE COMPLETA DE UTILIZA√á√ÉO DO TRANSPORTE")
    print("="*60)
    
    df = limpar_colunas(datasets['utiliza√ß√£o'].copy())
    
    # Identificar colunas
    modal_col = None
    license_col = None
    vehicle_col = None
    frequency_col = None
    payment_col = None
    
    for col in df.columns:
        if 'forma' in col.lower() and 'viagens' in col.lower():
            modal_col = col
        elif 'carteira' in col.lower() and 'motorista' in col.lower():
            license_col = col
        elif 've√≠culo pr√≥prio' in col.lower() or 'veiculo proprio' in col.lower():
            vehicle_col = col
        elif 'frequ√™ncia' in col.lower() or 'frequencia' in col.lower():
            frequency_col = col
        elif 'pagamento' in col.lower():
            payment_col = col
    
    resultados = {}
    
    # 1. AN√ÅLISE MODAL
    if modal_col:
        print(f"\n1. DISTRIBUI√á√ÉO MODAL (Principal meio de transporte)")
        print("-"*50)
        modal_dist = df[modal_col].value_counts()
        modal_pct = df[modal_col].value_counts(normalize=True) * 100
        
        for cat, count in modal_dist.items():
            pct = modal_pct[cat]
            print(f"  {cat}: {count} ({pct:.1f}%)")
        
        resultados['modal'] = {
            'distribuicao': modal_dist.to_dict(),
            'percentuais': modal_pct.to_dict()
        }
    
    # 2. AN√ÅLISE DE CARTEIRA DE MOTORISTA
    if license_col:
        print(f"\n2. POSSE DE CARTEIRA DE MOTORISTA")
        print("-"*35)
        license_dist = df[license_col].value_counts()
        license_pct = df[license_col].value_counts(normalize=True) * 100
        
        for cat, count in license_dist.items():
            pct = license_pct[cat]
            print(f"  {cat}: {count} ({pct:.1f}%)")
        
        # Categorizar por tipo
        tem_carteira = df[license_col] != 'N√£o tenho'
        pct_com_carteira = tem_carteira.sum() / len(df) * 100
        print(f"\n  RESUMO: {pct_com_carteira:.1f}% possuem algum tipo de carteira")
        
        resultados['carteira'] = {
            'distribuicao': license_dist.to_dict(),
            'percentuais': license_pct.to_dict(),
            'percentual_com_carteira': pct_com_carteira
        }
    
    # 3. AN√ÅLISE DE VE√çCULO PR√ìPRIO
    if vehicle_col:
        print(f"\n3. POSSE DE VE√çCULO PR√ìPRIO")
        print("-"*30)
        vehicle_dist = df[vehicle_col].value_counts()
        vehicle_pct = df[vehicle_col].value_counts(normalize=True) * 100
        
        for cat, count in vehicle_dist.items():
            pct = vehicle_pct[cat]
            print(f"  {cat}: {count} ({pct:.1f}%)")
        
        resultados['veiculo'] = {
            'distribuicao': vehicle_dist.to_dict(),
            'percentuais': vehicle_pct.to_dict()
        }
    
    # 4. AN√ÅLISE DE FREQU√äNCIA DE USO DO TP
    if frequency_col:
        print(f"\n4. FREQU√äNCIA DE USO DO TRANSPORTE P√öBLICO")
        print("-"*45)
        freq_dist = df[frequency_col].value_counts()
        freq_pct = df[frequency_col].value_counts(normalize=True) * 100
        
        for cat, count in freq_dist.items():
            pct = freq_pct[cat]
            print(f"  {cat}: {count} ({pct:.1f}%)")
        
        # Categorizar usu√°rios
        usuarios_ativos = ~df[frequency_col].str.contains('N√£o utilizo', na=False)
        pct_usuarios = usuarios_ativos.sum() / len(df) * 100
        print(f"\n  RESUMO: {pct_usuarios:.1f}% s√£o usu√°rios ativos do transporte p√∫blico")
        
        resultados['frequencia'] = {
            'distribuicao': freq_dist.to_dict(),
            'percentuais': freq_pct.to_dict(),
            'percentual_usuarios_ativos': pct_usuarios
        }
    
    # 5. AN√ÅLISE DE MEIO DE PAGAMENTO
    if payment_col:
        print(f"\n5. MEIO DE PAGAMENTO PREFERIDO")
        print("-"*30)
        payment_dist = df[payment_col].value_counts()
        payment_pct = df[payment_col].value_counts(normalize=True) * 100
        
        for cat, count in payment_dist.items():
            pct = payment_pct[cat]
            print(f"  {cat}: {count} ({pct:.1f}%)")
        
        resultados['pagamento'] = {
            'distribuicao': payment_dist.to_dict(),
            'percentuais': payment_pct.to_dict()
        }
    
    return resultados

def analises_cruzadas_avancadas(datasets):
    """An√°lises cruzadas avan√ßadas entre vari√°veis"""
    print("\nüîÑ AN√ÅLISES CRUZADAS AVAN√áADAS")
    print("="*50)
    
    # Combinar dados de perfil e utiliza√ß√£o
    perfil = limpar_colunas(datasets['perfil_socioeconomico'].copy())
    utilizacao = limpar_colunas(datasets['utiliza√ß√£o'].copy())
    
    # Merge dos dados
    dados_combinados = pd.merge(perfil, utilizacao, on='ID', how='inner')
    
    print(f"Dados combinados: {len(dados_combinados)} registros")
    
    resultados = {}
    
    # 1. ESCOLARIDADE vs USO DO TRANSPORTE P√öBLICO
    education_col = None
    modal_col = None
    
    for col in perfil.columns:
        if 'escolaridade' in col.lower():
            education_col = col
            break
    
    for col in utilizacao.columns:
        if 'forma' in col.lower() and 'viagens' in col.lower():
            modal_col = col
            break
    
    if education_col and modal_col:
        print(f"\n1. ESCOLARIDADE vs ESCOLHA MODAL")
        print("-"*35)
        
        tabela_cruzada = pd.crosstab(
            dados_combinados[education_col], 
            dados_combinados[modal_col], 
            normalize='index'
        ) * 100
        
        print("Percentual por linha (escolaridade):")
        for edu in tabela_cruzada.index:
            print(f"\n{edu}:")
            for modal in tabela_cruzada.columns:
                if tabela_cruzada.loc[edu, modal] > 5:  # S√≥ mostra se > 5%
                    print(f"  {modal}: {tabela_cruzada.loc[edu, modal]:.1f}%")
        
        # Teste qui-quadrado
        chi2, p_value, dof, expected = chi2_contingency(pd.crosstab(
            dados_combinados[education_col], 
            dados_combinados[modal_col]
        ))
        
        print(f"\nTeste Qui-quadrado: œá¬≤ = {chi2:.3f}, p = {p_value:.3f}")
        if p_value < 0.05:
            print("‚Üí H√° associa√ß√£o significativa entre escolaridade e escolha modal")
        else:
            print("‚Üí N√£o h√° associa√ß√£o significativa")
        
        resultados['escolaridade_modal'] = {
            'tabela_cruzada': tabela_cruzada.to_dict(),
            'chi2': chi2,
            'p_value': p_value,
            'significativo': p_value < 0.05
        }
    
    # 2. ETNIA vs USO DO TRANSPORTE P√öBLICO
    race_col = None
    for col in perfil.columns:
        if 'ra√ßa' in col.lower() or 'raca' in col.lower():
            race_col = col
            break
    
    if race_col and modal_col:
        print(f"\n2. ETNIA vs ESCOLHA MODAL")
        print("-"*25)
        
        tabela_cruzada_raca = pd.crosstab(
            dados_combinados[race_col], 
            dados_combinados[modal_col], 
            normalize='index'
        ) * 100
        
        print("Percentual por linha (etnia):")
        for raca in tabela_cruzada_raca.index:
            uso_tp = 0
            if 'Utilizo o transporte p√∫blico' in tabela_cruzada_raca.columns:
                uso_tp = tabela_cruzada_raca.loc[raca, 'Utilizo o transporte p√∫blico']
            print(f"  {raca}: {uso_tp:.1f}% usam TP")
        
        resultados['etnia_modal'] = {
            'tabela_cruzada': tabela_cruzada_raca.to_dict()
        }
    
    # 3. CARTEIRA DE MOTORISTA vs USO DO TP
    license_col = None
    for col in utilizacao.columns:
        if 'carteira' in col.lower() and 'motorista' in col.lower():
            license_col = col
            break
    
    if license_col and modal_col:
        print(f"\n3. CARTEIRA DE MOTORISTA vs ESCOLHA MODAL")
        print("-"*40)
        
        # Simplificar categorias de carteira
        dados_combinados['tem_carteira'] = dados_combinados[license_col] != 'N√£o tenho'
        
        tabela_carteira = pd.crosstab(
            dados_combinados['tem_carteira'], 
            dados_combinados[modal_col], 
            normalize='index'
        ) * 100
        
        print("Percentual por posse de carteira:")
        for tem_carteira in [True, False]:
            label = "COM carteira" if tem_carteira else "SEM carteira"
            uso_tp = 0
            if 'Utilizo o transporte p√∫blico' in tabela_carteira.columns:
                uso_tp = tabela_carteira.loc[tem_carteira, 'Utilizo o transporte p√∫blico']
            print(f"  {label}: {uso_tp:.1f}% usam TP")
        
        resultados['carteira_modal'] = {
            'tabela_cruzada': tabela_carteira.to_dict()
        }
    
    # 4. RENDA vs USO DO TRANSPORTE P√öBLICO
    income_col = None
    for col in perfil.columns:
        if 'renda' in col.lower():
            income_col = col
            break
    
    if income_col and modal_col:
        print(f"\n4. RENDA vs ESCOLHA MODAL")
        print("-"*25)
        
        tabela_renda = pd.crosstab(
            dados_combinados[income_col], 
            dados_combinados[modal_col], 
            normalize='index'
        ) * 100
        
        print("Percentual por faixa de renda:")
        for renda in tabela_renda.index:
            uso_tp = 0
            if 'Utilizo o transporte p√∫blico' in tabela_renda.columns:
                uso_tp = tabela_renda.loc[renda, 'Utilizo o transporte p√∫blico']
            print(f"  {renda}: {uso_tp:.1f}% usam TP")
        
        resultados['renda_modal'] = {
            'tabela_cruzada': tabela_renda.to_dict()
        }
    
    return resultados

def analise_qualidade_detalhada(datasets):
    """An√°lise detalhada da qualidade do servi√ßo"""
    print("\n‚≠ê AN√ÅLISE DETALHADA DA QUALIDADE DO SERVI√áO")
    print("="*55)
    
    df = limpar_colunas(datasets['qualidade_do_servi√ßo'].copy())
    
    # Identificar colunas de qualidade (excluindo ID)
    quality_cols = [col for col in df.columns if col != 'ID']
    
    print(f"Atributos de qualidade analisados: {len(quality_cols)}")
    
    resultados = {}
    
    # 1. ESTAT√çSTICAS DESCRITIVAS POR ATRIBUTO
    print(f"\n1. ESTAT√çSTICAS DESCRITIVAS POR ATRIBUTO")
    print("-"*45)
    
    stats_summary = []
    
    for col in quality_cols:
        try:
            # Converter para num√©rico se poss√≠vel
            values = pd.to_numeric(df[col], errors='coerce')
            
            if values.notna().sum() > 0:
                media = values.mean()
                mediana = values.median()
                desvio = values.std()
                minimo = values.min()
                maximo = values.max()
                
                print(f"\n{col}:")
                print(f"  M√©dia: {media:.2f}")
                print(f"  Mediana: {mediana:.2f}")
                print(f"  Desvio Padr√£o: {desvio:.2f}")
                print(f"  Min-Max: {minimo:.1f} - {maximo:.1f}")
                
                stats_summary.append({
                    'atributo': col,
                    'media': media,
                    'mediana': mediana,
                    'desvio': desvio,
                    'min': minimo,
                    'max': maximo
                })
        except:
            print(f"  {col}: N√£o num√©rico")
    
    # 2. RANKING DOS ATRIBUTOS
    print(f"\n2. RANKING DOS ATRIBUTOS (por m√©dia)")
    print("-"*35)
    
    stats_df = pd.DataFrame(stats_summary)
    if not stats_df.empty:
        stats_df_sorted = stats_df.sort_values('media', ascending=False)
        
        print("Melhores avaliados:")
        for i, row in stats_df_sorted.head(5).iterrows():
            print(f"  {i+1}. {row['atributo']}: {row['media']:.2f}")
        
        print("\nPiores avaliados:")
        for i, row in stats_df_sorted.tail(5).iterrows():
            print(f"  {len(stats_df_sorted)-i}. {row['atributo']}: {row['media']:.2f}")
        
        resultados['ranking'] = {
            'melhores': stats_df_sorted.head(5).to_dict('records'),
            'piores': stats_df_sorted.tail(5).to_dict('records')
        }
    
    # 3. AN√ÅLISE DE CORRELA√á√ïES
    print(f"\n3. CORRELA√á√ïES ENTRE ATRIBUTOS")
    print("-"*30)
    
    # Criar matriz de dados num√©ricos
    numeric_data = pd.DataFrame()
    for col in quality_cols:
        values = pd.to_numeric(df[col], errors='coerce')
        if values.notna().sum() > 10:  # M√≠nimo de 10 valores v√°lidos
            numeric_data[col] = values
    
    if not numeric_data.empty:
        corr_matrix = numeric_data.corr()
        
        # Encontrar correla√ß√µes mais altas (excluindo diagonal)
        corr_pairs = []
        for i in range(len(corr_matrix.columns)):
            for j in range(i+1, len(corr_matrix.columns)):
                corr_val = corr_matrix.iloc[i, j]
                if not pd.isna(corr_val):
                    corr_pairs.append({
                        'atributo1': corr_matrix.columns[i],
                        'atributo2': corr_matrix.columns[j],
                        'correlacao': corr_val
                    })
        
        corr_pairs_df = pd.DataFrame(corr_pairs)
        corr_pairs_df = corr_pairs_df.sort_values('correlacao', key=abs, ascending=False)
        
        print("Correla√ß√µes mais fortes:")
        for _, row in corr_pairs_df.head(10).iterrows():
            print(f"  {row['atributo1']} ‚Üî {row['atributo2']}: {row['correlacao']:.3f}")
        
        resultados['correlacoes'] = corr_pairs_df.head(20).to_dict('records')
    
    return resultados

def analise_recompensas_detalhada(datasets):
    """An√°lise detalhada das percep√ß√µes sobre recompensas"""
    print("\nüéÅ AN√ÅLISE DETALHADA DE RECOMPENSAS")
    print("="*45)
    
    # Analisar percep√ß√£o e inten√ß√£o comportamental
    percepcao = limpar_colunas(datasets['percep√ß√£o_novos_servi√ßos'].copy())
    intencao = limpar_colunas(datasets['inten√ß√£o_comportamental'].copy())
    
    resultados = {}
    
    # 1. AN√ÅLISE DE PERCEP√á√ÉO
    print(f"\n1. AN√ÅLISE DE PERCEP√á√ÉO DE RECOMPENSAS")
    print("-"*40)
    
    perception_cols = [col for col in percepcao.columns if col != 'ID']
    
    perception_stats = []
    for col in perception_cols:
        values = pd.to_numeric(percepcao[col], errors='coerce')
        if values.notna().sum() > 0:
            media = values.mean()
            perception_stats.append({
                'tipo_recompensa': col,
                'media_percepcao': media
            })
    
    if perception_stats:
        perception_df = pd.DataFrame(perception_stats)
        perception_df = perception_df.sort_values('media_percepcao', ascending=False)
        
        print("Recompensas mais valorizadas:")
        for _, row in perception_df.head(5).iterrows():
            print(f"  {row['tipo_recompensa']}: {row['media_percepcao']:.2f}")
        
        resultados['percepcao'] = perception_df.to_dict('records')
    
    # 2. AN√ÅLISE DE INTEN√á√ÉO COMPORTAMENTAL
    print(f"\n2. AN√ÅLISE DE INTEN√á√ÉO COMPORTAMENTAL")
    print("-"*40)
    
    intention_cols = [col for col in intencao.columns if col != 'ID']
    
    intention_stats = []
    for col in intention_cols:
        values = pd.to_numeric(intencao[col], errors='coerce')
        if values.notna().sum() > 0:
            media = values.mean()
            intention_stats.append({
                'tipo_incentivo': col,
                'media_intencao': media
            })
    
    if intention_stats:
        intention_df = pd.DataFrame(intention_stats)
        intention_df = intention_df.sort_values('media_intencao', ascending=False)
        
        print("Incentivos com maior potencial:")
        for _, row in intention_df.head(5).iterrows():
            print(f"  {row['tipo_incentivo']}: {row['media_intencao']:.2f}")
        
        resultados['intencao'] = intention_df.to_dict('records')
    
    return resultados

def gerar_relatorio_expandido(datasets, all_results):
    """Gerar relat√≥rio expandido completo"""
    print("\nüìä GERANDO RELAT√ìRIO EXPANDIDO COMPLETO")
    print("="*50)
    
    timestamp = pd.Timestamp.now().strftime("%Y%m%d_%H%M%S")
    filename = f"RELATORIO_EXPANDIDO_COMPLETO_{timestamp}.md"
    
    with open(filename, 'w', encoding='utf-8') as f:
        f.write("# RELAT√ìRIO EXPANDIDO COMPLETO - AN√ÅLISE DE TRANSPORTE P√öBLICO E RECOMPENSAS\n\n")
        f.write(f"**Data de Gera√ß√£o:** {pd.Timestamp.now().strftime('%d/%m/%Y %H:%M:%S')}\n\n")
        f.write("---\n\n")
        
        # Resumo Executivo
        f.write("## RESUMO EXECUTIVO\n\n")
        f.write("Esta an√°lise expandida apresenta insights detalhados sobre:\n")
        f.write("- **Perfil Socioecon√¥mico Completo**: G√™nero, etnia, escolaridade, renda, situa√ß√£o profissional\n")
        f.write("- **Comportamento de Utiliza√ß√£o**: Modal split, posse de carteira, ve√≠culo pr√≥prio\n")
        f.write("- **Qualidade do Servi√ßo**: Avalia√ß√£o detalhada de todos os atributos\n")
        f.write("- **Sistema de Recompensas**: Percep√ß√£o e inten√ß√£o comportamental\n")
        f.write("- **An√°lises Cruzadas**: Intera√ß√µes entre vari√°veis socioecon√¥micas e uso do transporte\n\n")
        
        # Perfil Socioecon√¥mico
        if 'perfil' in all_results:
            f.write("## 1. PERFIL SOCIOECON√îMICO DETALHADO\n\n")
            
            perfil_results = all_results['perfil']
            
            if 'genero' in perfil_results:
                f.write("### 1.1 Distribui√ß√£o por G√™nero\n\n")
                for cat, pct in perfil_results['genero']['percentuais'].items():
                    f.write(f"- **{cat}**: {pct:.1f}%\n")
                f.write("\n")
            
            if 'raca' in perfil_results:
                f.write("### 1.2 Distribui√ß√£o por Etnia/Ra√ßa\n\n")
                for cat, pct in perfil_results['raca']['percentuais'].items():
                    f.write(f"- **{cat}**: {pct:.1f}%\n")
                f.write("\n")
            
            if 'escolaridade' in perfil_results:
                f.write("### 1.3 Distribui√ß√£o por Escolaridade\n\n")
                for cat, pct in perfil_results['escolaridade']['percentuais'].items():
                    f.write(f"- **{cat}**: {pct:.1f}%\n")
                f.write("\n")
            
            if 'renda' in perfil_results:
                f.write("### 1.4 Distribui√ß√£o por Renda\n\n")
                for cat, pct in perfil_results['renda']['percentuais'].items():
                    f.write(f"- **{cat}**: {pct:.1f}%\n")
                f.write("\n")
        
        # Utiliza√ß√£o
        if 'utilizacao' in all_results:
            f.write("## 2. AN√ÅLISE DE UTILIZA√á√ÉO DO TRANSPORTE\n\n")
            
            util_results = all_results['utilizacao']
            
            if 'carteira' in util_results:
                f.write("### 2.1 Posse de Carteira de Motorista\n\n")
                f.write(f"**{util_results['carteira']['percentual_com_carteira']:.1f}% possuem algum tipo de carteira**\n\n")
                for cat, pct in util_results['carteira']['percentuais'].items():
                    f.write(f"- **{cat}**: {pct:.1f}%\n")
                f.write("\n")
            
            if 'modal' in util_results:
                f.write("### 2.2 Distribui√ß√£o Modal\n\n")
                for cat, pct in util_results['modal']['percentuais'].items():
                    f.write(f"- **{cat}**: {pct:.1f}%\n")
                f.write("\n")
        
        # Qualidade
        if 'qualidade' in all_results:
            f.write("## 3. AN√ÅLISE DE QUALIDADE DO SERVI√áO\n\n")
            
            qual_results = all_results['qualidade']
            
            if 'ranking' in qual_results:
                f.write("### 3.1 Ranking de Atributos\n\n")
                f.write("**Melhores Avaliados:**\n")
                for i, attr in enumerate(qual_results['ranking']['melhores'], 1):
                    f.write(f"{i}. **{attr['atributo']}**: {attr['media']:.2f}\n")
                
                f.write("\n**Piores Avaliados:**\n")
                for i, attr in enumerate(qual_results['ranking']['piores'], 1):
                    f.write(f"{i}. **{attr['atributo']}**: {attr['media']:.2f}\n")
                f.write("\n")
        
        # An√°lises Cruzadas
        if 'cruzadas' in all_results:
            f.write("## 4. AN√ÅLISES CRUZADAS\n\n")
            
            cruz_results = all_results['cruzadas']
            
            if 'escolaridade_modal' in cruz_results and cruz_results['escolaridade_modal']['significativo']:
                f.write("### 4.1 Escolaridade vs Escolha Modal\n\n")
                f.write(f"**Teste Qui-quadrado**: œá¬≤ = {cruz_results['escolaridade_modal']['chi2']:.3f}, ")
                f.write(f"p = {cruz_results['escolaridade_modal']['p_value']:.3f}\n")
                f.write("‚Üí **H√° associa√ß√£o significativa entre escolaridade e escolha modal**\n\n")
        
        f.write("---\n\n")
        f.write("## CONCLUS√ïES E RECOMENDA√á√ïES\n\n")
        f.write("### Principais Insights:\n\n")
        f.write("1. **Perfil Diversificado**: Base de usu√°rios heterog√™nea em termos socioecon√¥micos\n")
        f.write("2. **Oportunidades de Melhoria**: Atributos cr√≠ticos identificados na qualidade\n")
        f.write("3. **Potencial de Recompensas**: Sistema de incentivos com alto potencial\n")
        f.write("4. **Segmenta√ß√£o Relevante**: Diferen√ßas comportamentais por perfil socioecon√¥mico\n\n")
        
        f.write("### Recomenda√ß√µes Estrat√©gicas:\n\n")
        f.write("1. **Melhoria Direcionada**: Focar nos atributos de menor avalia√ß√£o\n")
        f.write("2. **Segmenta√ß√£o de Pol√≠ticas**: Adaptar estrat√©gias por perfil socioecon√¥mico\n")
        f.write("3. **Sistema de Recompensas**: Implementar programa de incentivos\n")
        f.write("4. **Monitoramento Cont√≠nuo**: Acompanhar evolu√ß√£o dos indicadores\n\n")
    
    print(f"‚úì Relat√≥rio salvo como: {filename}")
    return filename

def main():
    """Fun√ß√£o principal para executar toda a an√°lise expandida"""
    print("üöÄ INICIANDO AN√ÅLISE EXPANDIDA COMPLETA")
    print("="*60)
    
    # Carregar dados
    datasets = carregar_dados()
    
    if not datasets:
        print("‚ùå Nenhum dataset carregado. Verificar arquivos CSV.")
        return
    
    # Executar todas as an√°lises
    all_results = {}
    
    try:
        # 1. Perfil Socioecon√¥mico
        all_results['perfil'] = analise_perfil_socioeconomico_completa(datasets)
        
        # 2. Utiliza√ß√£o
        all_results['utilizacao'] = analise_utilizacao_completa(datasets)
        
        # 3. Qualidade
        all_results['qualidade'] = analise_qualidade_detalhada(datasets)
        
        # 4. Recompensas
        all_results['recompensas'] = analise_recompensas_detalhada(datasets)
        
        # 5. An√°lises Cruzadas
        all_results['cruzadas'] = analises_cruzadas_avancadas(datasets)
        
        # 6. Gerar relat√≥rio
        relatorio = gerar_relatorio_expandido(datasets, all_results)
        
        print(f"\nüéâ AN√ÅLISE EXPANDIDA CONCLU√çDA COM SUCESSO!")
        print(f"üìÑ Relat√≥rio gerado: {relatorio}")
        
    except Exception as e:
        print(f"‚ùå Erro durante a an√°lise: {e}")
        import traceback
        traceback.print_exc()

if __name__ == "__main__":
    main() 